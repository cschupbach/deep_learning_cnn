{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Chad Schupbach}$$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common CNN feature learning architecture is similar to that shown above, where feature maps are constructed with ReLU-activated convolutional layers and intermittent max pooling. It's also fairly common to normalize the batch of input layers prior to convolution in the feature learning segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "In the classification segment of the network, we flatten the final laywe shift our focus to classification using fully connected (FC) layers.\n",
    "\n",
    "### Fully Connected (FC) Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, input_shape = utils.load_mnist(method='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} \\underset{28 \\times 28 \\times 1}{ \\ \\ \\textsf{input}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{28 \\times 28 \\times 16}{ \\ \\ \\textsf{conv1}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{28 \\times 28 \\times 16}{\\textsf{conv2}^\\dagger} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto}\\\\[5pt]\n",
    "\\underset{14 \\times 14 \\times 16}{ \\, \\ \\textsf{pool1}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{14 \\times 14 \\times 32}{\\textsf{conv3}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{14 \\times 14 \\times 32}{\\textsf{conv4}^\\dagger} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto}\\\\[5pt]\n",
    "\\underset{7 \\times 7 \\times 32}{ \\, \\ \\textsf{pool2}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv5}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv6}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto}\\\\[5pt] \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv7}^\\dagger} \\ \\ _{ + \\ \\ \\text{flatten}_{1600} \\ + \\ \\text{dropout}_{0.25} \\ + \\ \\text{dense}_{128} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto}\\\\[10pt]\n",
    "\\underset{1 \\times 1 \\times 128}{\\textsf{FC6}} \\ \\ _{ + \\ \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{128} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 128}{\\textsf{FC7}} \\ \\ _{ + \\ \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{10} \\ + \\ \\text{Softmax} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 10}{\\textsf{output}} \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we introduce FC layers by building a network beginning with feature learning. We initialize a Keras sequential model object as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning with the architecture\n",
    "\n",
    "$$\\underset{30 \\times 30 \\times 1}{ \\ \\ \\textsf{input}^+} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{30 \\times 30 \\times 32}{ \\ \\ \\textsf{conv1}^+} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{28 \\times 28 \\times 64}{\\textsf{conv2}} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto} \\ \\ \\underset{16 \\times 16 \\times 64}{ \\, \\ \\textsf{pool1}^\\ddagger}$$\n",
    "\n",
    "we add layers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{16 \\times 16 \\times 64}{ \\, \\ \\textsf{pool1}^\\ddagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{14 \\times 14 \\times 64}{\\textsf{conv3}} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto} \\ \\ \\underset{8 \\times 8 \\times 64}{ \\, \\ \\textsf{pool2}^\\ddagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv4}^\\dagger}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we switch over to classification by vectorizing `conv5` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv4}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{5 \\times 5 \\times 64}{ \\, \\ \\textsf{conv5}^\\dagger} \\ \\ _{ + \\ \\ \\text{flatten}_{1600} \\ + \\ \\text{dropout}_{0.25} \\ + \\ \\text{dense}_{156} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 156}{\\textsf{FC6}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{1 \\times 1 \\times 156}{\\textsf{FC6}} \\ \\ _{ + \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{156} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 156}{\\textsf{FC7}} \\ \\ _{ + \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{10} \\ + \\ \\text{Softmax} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 10}{\\textsf{output}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 257,722\n",
      "Trainable params: 257,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = 'models/best_weights.hdf5'\n",
    "# checkpoint = ModelCheckpoint(fp, monitor='val_accuracy', save_best_only=True,\n",
    "#                              save_weights_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='nadam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.4966 - accuracy: 0.8381 - val_loss: 0.0673 - val_accuracy: 0.9805\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 52s 1ms/sample - loss: 0.1167 - accuracy: 0.9694 - val_loss: 0.0479 - val_accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64e90e950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1,\n",
    "          validation_split=0.2, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr = np.array([\n",
    "    [0.4583, 0.8572, 0.0730, 0.9807],\n",
    "    [0.1046, 0.9735, 0.0512, 0.9858],\n",
    "    [0.0736, 0.9824, 0.0437, 0.9881],\n",
    "    [0.0604, 0.9842, 0.0519, 0.9869],\n",
    "    [0.0525, 0.9870, 0.0328, 0.9908],\n",
    "    [0.0448, 0.9886, 0.0461, 0.9906],\n",
    "    [0.0451, 0.9883, 0.0405, 0.9900],\n",
    "    [0.0397, 0.9902, 0.0375, 0.9908],\n",
    "    [0.0398, 0.9899, 0.0419, 0.9915],\n",
    "    [0.0385, 0.9900, 0.0642, 0.9860],\n",
    "    [0.0395, 0.9901, 0.0477, 0.9908],\n",
    "    [0.0298, 0.9924, 0.0591, 0.9895],\n",
    "    [0.0341, 0.9912, 0.0415, 0.9914],\n",
    "    [0.0316, 0.9919, 0.0417, 0.9908],\n",
    "    [0.0293, 0.9928, 0.0371, 0.9915],\n",
    "    [0.0310, 0.9923, 0.0379, 0.9910],\n",
    "    [0.0304, 0.9923, 0.0412, 0.9925],\n",
    "    [0.0288, 0.9928, 0.0576, 0.9890],\n",
    "    [0.0282, 0.9934, 0.0421, 0.9925],\n",
    "    [0.0286, 0.9924, 0.0522, 0.9902],\n",
    "    [0.0301, 0.9930, 0.0511, 0.9898],\n",
    "    [0.0266, 0.9932, 0.0459, 0.9897],\n",
    "    [0.0243, 0.9940, 0.0494, 0.9925],\n",
    "    [0.0275, 0.9934, 0.0537, 0.9903],\n",
    "    [0.0261, 0.9934, 0.0435, 0.9930],\n",
    "    [0.0264, 0.9938, 0.0483, 0.9909],\n",
    "    [0.0216, 0.9947, 0.0526, 0.9912],\n",
    "    [0.0260, 0.9938, 0.0441, 0.9918],\n",
    "    [0.0267, 0.9937, 0.0476, 0.9918],\n",
    "    [0.0244, 0.9942, 0.0559, 0.9904],\n",
    "    [0.0281, 0.9936, 0.0619, 0.9909],\n",
    "    [0.0269, 0.9935, 0.0666, 0.9913],\n",
    "    [0.0347, 0.9920, 0.0548, 0.9881],\n",
    "    [0.0318, 0.9928, 0.0556, 0.9906],\n",
    "    [0.0248, 0.9943, 0.0445, 0.9912],\n",
    "    [0.0261, 0.9936, 0.0579, 0.9924],\n",
    "    [0.0221, 0.9950, 0.0581, 0.9914],\n",
    "    [0.0188, 0.9957, 0.0693, 0.9912],\n",
    "    [0.0216, 0.9948, 0.0700, 0.9915],\n",
    "    [0.0309, 0.9932, 0.0572, 0.9906],\n",
    "    [0.0234, 0.9942, 0.0718, 0.9917],\n",
    "    [0.0320, 0.9930, 0.0601, 0.9908],\n",
    "    [0.0235, 0.9952, 0.0551, 0.9920],\n",
    "    [0.0237, 0.9946, 0.0818, 0.9904],\n",
    "    [0.0361, 0.9921, 0.0654, 0.9923],\n",
    "    [0.0191, 0.9953, 0.0763, 0.9923],\n",
    "    [0.0296, 0.9942, 0.0631, 0.9925],\n",
    "    [0.0198, 0.9956, 0.0727, 0.9925],\n",
    "    [0.0307, 0.9933, 0.0737, 0.9914],\n",
    "    [0.0218, 0.9949, 0.0772, 0.9921]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arr[1:,[1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0395 - accuracy: 0.9901 - val_loss: 0.0477 - val_accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0298 - accuracy: 0.9924 - val_loss: 0.0591 - val_accuracy: 0.9895\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0415 - val_accuracy: 0.9914\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.0417 - val_accuracy: 0.9908\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.0371 - val_accuracy: 0.9915\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0310 - accuracy: 0.9923 - val_loss: 0.0379 - val_accuracy: 0.9910\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.0412 - val_accuracy: 0.9925\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9890\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.0421 - val_accuracy: 0.9925\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.0522 - val_accuracy: 0.9902\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0511 - val_accuracy: 0.9898\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.0459 - val_accuracy: 0.9897\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0494 - val_accuracy: 0.9925\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0275 - accuracy: 0.9934 - val_loss: 0.0537 - val_accuracy: 0.9903\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0261 - accuracy: 0.9934 - val_loss: 0.0435 - val_accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.0483 - val_accuracy: 0.9909\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.0526 - val_accuracy: 0.9912\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.0441 - val_accuracy: 0.9918\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0476 - val_accuracy: 0.9918\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.0559 - val_accuracy: 0.9904\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.0619 - val_accuracy: 0.9909\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.0666 - val_accuracy: 0.9913\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0347 - accuracy: 0.9920 - val_loss: 0.0548 - val_accuracy: 0.9881\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0318 - accuracy: 0.9928 - val_loss: 0.0556 - val_accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.0445 - val_accuracy: 0.9912\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0261 - accuracy: 0.9936 - val_loss: 0.0579 - val_accuracy: 0.9924\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.0581 - val_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0693 - val_accuracy: 0.9912\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.0700 - val_accuracy: 0.9915\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0309 - accuracy: 0.9932 - val_loss: 0.0572 - val_accuracy: 0.9906\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.0718 - val_accuracy: 0.9917\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 0.0601 - val_accuracy: 0.9908\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0235 - accuracy: 0.9952 - val_loss: 0.0551 - val_accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.0818 - val_accuracy: 0.9904\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0361 - accuracy: 0.9921 - val_loss: 0.0654 - val_accuracy: 0.9923\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.0763 - val_accuracy: 0.9923\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0631 - val_accuracy: 0.9925\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.0727 - val_accuracy: 0.9925\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 0.0737 - val_accuracy: 0.9914\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0772 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64f2a19d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1,\n",
    "#           validation_split=0.2, initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=30, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=40, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(fp)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_metadata": {
   "date": "May 4, 2020"
  },
  "title": "CNN Architecture II"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
