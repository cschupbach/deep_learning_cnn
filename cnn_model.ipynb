{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Chad Schupbach}$$\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common CNN feature learning architecture is similar to that shown above, where feature maps are constructed with ReLU-activated convolutional layers and intermittent max pooling. It's also fairly common to normalize the batch of input layers prior to convolution in the feature learning segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "In the classification segment of the network, we flatten the final laywe shift our focus to classification using fully connected (FC) layers.\n",
    "\n",
    "### Fully Connected (FC) Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} \\underset{28 \\times 28 \\times 1}{ \\ \\ \\textsf{input}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{28 \\times 28 \\times 16}{ \\ \\ \\textsf{conv1}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{28 \\times 28 \\times 16}{\\textsf{conv2}^\\dagger} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto}\\\\[5pt]\n",
    "\\underset{14 \\times 14 \\times 16}{ \\, \\ \\textsf{pool1}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{14 \\times 14 \\times 32}{\\textsf{conv3}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{14 \\times 14 \\times 32}{\\textsf{conv4}^\\dagger} \\ \\ _{ \\ast \\ \\ \\text{max pool}_{2 \\times 2} \\ \\ \\longmapsto}\\\\[5pt]\n",
    "\\underset{7 \\times 7 \\times 32}{ \\, \\ \\textsf{pool2}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv5}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv6}^\\dagger} \\ \\ _{\\circledast \\ \\ \\text{conv}_{3 \\times 3} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto}\\\\[5pt] \\underset{7 \\times 7 \\times 64}{ \\, \\ \\textsf{conv7}^\\dagger} \\ \\ _{ + \\ \\ \\text{flatten}_{1600} \\ + \\ \\text{dropout}_{0.25} \\ + \\ \\text{dense}_{128} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto}\\\\[10pt]\n",
    "\\underset{1 \\times 1 \\times 128}{\\textsf{FC6}} \\ \\ _{ + \\ \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{128} \\ + \\ \\text{ReLU} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 128}{\\textsf{FC7}} \\ \\ _{ + \\ \\ \\text{dropout}_{0.5} \\ + \\ \\text{dense}_{10} \\ + \\ \\text{Softmax} \\ \\ \\longmapsto} \\ \\ \\underset{1 \\times 1 \\times 10}{\\textsf{output}} \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the entire MNIST dataset containing 60000 training images and 10000 testing images across 10 classes $\\{0,1,\\dots,8,9\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, input_shape = utils.load_mnist(method='keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ensemble, we will train 5 models with the same architecture using a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 128\n",
    "n_models = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of each CNN model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [None] * n_models\n",
    "for i in range(n_models):\n",
    "    model[i] = Sequential()\n",
    "    model[i].add(Conv2D(16, 3, padding='same', activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "    model[i].add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "    model[i].add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model[i].add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model[i].add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model[i].add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model[i].add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model[i].add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model[i].add(Conv2D(64, 3, activation='relu'))\n",
    "    model[i].add(Flatten())\n",
    "    model[i].add(Dropout(0.25))\n",
    "    model[i].add(Dense(batch_size, activation='relu'))\n",
    "    model[i].add(Dropout(0.5))\n",
    "    model[i].add(Dense(batch_size, activation='relu'))\n",
    "    model[i].add(Dropout(0.5))\n",
    "    model[i].add(Dense(n_classes, activation='softmax'))\n",
    "    model[i].compile(optimizer='nadam', loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 331,450\n",
      "Trainable params: 331,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign model checkpoints and early stopping criterion below. The checkpoints save parameter weights of the best training epoch based on validation accuracy to files in the `models` directory. We also set early stopping criterion that indicates convergence when no decrease in validation loss is observed over 8 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = []\n",
    "earlystop = []\n",
    "for i in range(n_models):\n",
    "    checkpoint += [ModelCheckpoint(filepath=f'models/best_weights_{i+1}.hdf5',\n",
    "                                   monitor='val_accuracy', save_best_only=True,\n",
    "                                   save_weights_only=True, mode='max')]\n",
    "    earlystop += [EarlyStopping(monitor='val_loss', patience=8, mode='min')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the early stopping criterion is not met, we end the training session of each model after 25 epochs. Because we need a validation set for the checkpoints and convergence criterion, we randomly split the training data into 80% training and 20% validation prior to each training session. It's not uncommon to see similar models implemented using the testing set for model validation. While it's tempting given that the validation set is not actually being used in training, this strategy will result in model selection bias and should be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_10\n",
      "==================================================\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/25\n",
      "48000/48000 [==============================] - 47s 973us/step - loss: 0.4115 - accuracy: 0.8711 - val_loss: 0.0706 - val_accuracy: 0.9822\n",
      "Epoch 2/25\n",
      "48000/48000 [==============================] - 44s 925us/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 0.0534 - val_accuracy: 0.9859\n",
      "Epoch 3/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0685 - accuracy: 0.9829 - val_loss: 0.0441 - val_accuracy: 0.9887\n",
      "Epoch 4/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0560 - accuracy: 0.9864 - val_loss: 0.0492 - val_accuracy: 0.9866\n",
      "Epoch 5/25\n",
      "48000/48000 [==============================] - 44s 925us/step - loss: 0.0527 - accuracy: 0.9867 - val_loss: 0.0386 - val_accuracy: 0.9893\n",
      "Epoch 6/25\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.0402 - accuracy: 0.9907 - val_loss: 0.0381 - val_accuracy: 0.9907\n",
      "Epoch 7/25\n",
      "48000/48000 [==============================] - 45s 928us/step - loss: 0.0427 - accuracy: 0.9896 - val_loss: 0.0396 - val_accuracy: 0.9902\n",
      "Epoch 8/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0362 - accuracy: 0.9907 - val_loss: 0.0430 - val_accuracy: 0.9902\n",
      "Epoch 9/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0408 - accuracy: 0.9898 - val_loss: 0.0414 - val_accuracy: 0.9898\n",
      "Epoch 10/25\n",
      "48000/48000 [==============================] - 45s 927us/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0353 - val_accuracy: 0.9919\n",
      "Epoch 11/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.0392 - val_accuracy: 0.9913\n",
      "Epoch 12/25\n",
      "48000/48000 [==============================] - 45s 928us/step - loss: 0.0323 - accuracy: 0.9923 - val_loss: 0.0377 - val_accuracy: 0.9904\n",
      "Epoch 13/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.0449 - val_accuracy: 0.9916\n",
      "Epoch 14/25\n",
      "48000/48000 [==============================] - 45s 927us/step - loss: 0.0322 - accuracy: 0.9927 - val_loss: 0.0373 - val_accuracy: 0.9913\n",
      "Epoch 15/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 0.0334 - val_accuracy: 0.9928\n",
      "Epoch 16/25\n",
      "48000/48000 [==============================] - 44s 926us/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.0388 - val_accuracy: 0.9923\n",
      "Epoch 17/25\n",
      "48000/48000 [==============================] - 44s 925us/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.0364 - val_accuracy: 0.9927\n",
      "Epoch 18/25\n",
      "48000/48000 [==============================] - 45s 928us/step - loss: 0.0292 - accuracy: 0.9928 - val_loss: 0.0444 - val_accuracy: 0.9907\n",
      "Epoch 19/25\n",
      "48000/48000 [==============================] - 45s 928us/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.0417 - val_accuracy: 0.9911\n",
      "Epoch 20/25\n",
      "48000/48000 [==============================] - 45s 927us/step - loss: 0.0247 - accuracy: 0.9939 - val_loss: 0.0490 - val_accuracy: 0.9896\n",
      "Epoch 21/25\n",
      "48000/48000 [==============================] - 44s 927us/step - loss: 0.0354 - accuracy: 0.9919 - val_loss: 0.0642 - val_accuracy: 0.9892\n",
      "Epoch 22/25\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.0243 - accuracy: 0.9943 - val_loss: 0.0478 - val_accuracy: 0.9898\n",
      "Epoch 23/25\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.0412 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "ledger = []\n",
    "for i in range(n_models):\n",
    "    clear_output(wait=True)\n",
    "    print(f'CNN_{i+1}\\n' + '='*50)\n",
    "    x_train2, x_valid, y_train2, y_valid = train_test_split(x_train, y_train,\n",
    "                                                            test_size=0.2)\n",
    "    ledger += [model[i].fit(x_train2, y_train2, batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, callbacks=[checkpoint[i], earlystop[i]],\n",
    "                            validation_data=(x_valid, y_valid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_epoch = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "for i in range(n_models):\n",
    "    opt_epoch += [np.argmax(ledger[i].history['val_accuracy']) + 1]\n",
    "    train_loss += [np.min(ledger[i].history['loss'])]\n",
    "    train_acc += [np.max(ledger[i].history['accuracy'])]\n",
    "    val_loss += [np.min(ledger[i].history['val_loss'])]\n",
    "    val_acc += [np.max(ledger[i].history['val_accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_acc = []\n",
    "for i in range(n_models):\n",
    "    model[i].load_weights(f'models/best_weights_{i+1}.hdf5')\n",
    "    score = model[i].evaluate(x_test, y_test, verbose=0)\n",
    "    test_loss += [score[0]]\n",
    "    test_acc += [score[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Opt Epoch': opt_epoch + [np.mean(opt_epoch)],\n",
    "    'Train Loss': train_loss + [np.mean(train_loss)],\n",
    "    'Valid Loss': val_loss + [np.mean(val_loss)],\n",
    "    'Test Loss': test_loss + [np.mean(test_loss)],\n",
    "    'Train Acc': train_acc + [np.mean(train_acc)],\n",
    "    'Valid Acc': val_acc + [np.mean(val_acc)],\n",
    "    'Test Acc': test_acc + [np.mean(test_acc)]\n",
    "}, index=[f'Model {i+1}' for i in range(n_models)] + ['Average']).round(5).round({\n",
    "    'Train Acc': 4,\n",
    "    'Valid Acc': 4,\n",
    "    'Test Acc': 4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opt Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Valid Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.02268</td>\n",
       "      <td>0.03259</td>\n",
       "      <td>0.03060</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.02162</td>\n",
       "      <td>0.02976</td>\n",
       "      <td>0.03487</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.02584</td>\n",
       "      <td>0.04130</td>\n",
       "      <td>0.03551</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.02234</td>\n",
       "      <td>0.04165</td>\n",
       "      <td>0.03103</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.9924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.02704</td>\n",
       "      <td>0.03801</td>\n",
       "      <td>0.02933</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.02132</td>\n",
       "      <td>0.03396</td>\n",
       "      <td>0.03077</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.9924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 7</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.02626</td>\n",
       "      <td>0.03635</td>\n",
       "      <td>0.03011</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.02871</td>\n",
       "      <td>0.04469</td>\n",
       "      <td>0.03480</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.02939</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.04206</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.02196</td>\n",
       "      <td>0.03338</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0.02472</td>\n",
       "      <td>0.03690</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.9927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Opt Epoch  Train Loss  Valid Loss  Test Loss  Train Acc  Valid Acc  \\\n",
       "Model 1         8.0     0.02268     0.03259    0.03060     0.9948     0.9920   \n",
       "Model 2        11.0     0.02162     0.02976    0.03487     0.9946     0.9930   \n",
       "Model 3        17.0     0.02584     0.04130    0.03551     0.9935     0.9917   \n",
       "Model 4        11.0     0.02234     0.04165    0.03103     0.9944     0.9916   \n",
       "Model 5         9.0     0.02704     0.03801    0.02933     0.9926     0.9912   \n",
       "Model 6        20.0     0.02132     0.03396    0.03077     0.9950     0.9923   \n",
       "Model 7        18.0     0.02626     0.03635    0.03011     0.9935     0.9921   \n",
       "Model 8        13.0     0.02871     0.04469    0.03480     0.9930     0.9908   \n",
       "Model 9         9.0     0.02939     0.03729    0.04206     0.9926     0.9911   \n",
       "Model 10       15.0     0.02196     0.03338    0.03078     0.9949     0.9928   \n",
       "Average        13.1     0.02472     0.03690    0.03299     0.9939     0.9919   \n",
       "\n",
       "          Test Acc  \n",
       "Model 1     0.9927  \n",
       "Model 2     0.9925  \n",
       "Model 3     0.9928  \n",
       "Model 4     0.9924  \n",
       "Model 5     0.9933  \n",
       "Model 6     0.9924  \n",
       "Model 7     0.9929  \n",
       "Model 8     0.9931  \n",
       "Model 9     0.9920  \n",
       "Model 10    0.9927  \n",
       "Average     0.9927  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = np.zeros(y_train.shape)\n",
    "test_res = np.zeros(y_test.shape)\n",
    "for i in range(n_models):\n",
    "    train_res += model[i].predict(x_train)\n",
    "    test_res += model[i].predict(x_test)\n",
    "train_res /= n_models\n",
    "test_res /= n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Train Accuracy: 0.99895\n",
      "Ensemble Test Accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "train_pred = np.argmax(train_res, axis=1)\n",
    "train_act = np.argmax(y_train, axis=1)\n",
    "ens_train_acc = (train_pred == train_act).mean()\n",
    "test_pred = np.argmax(test_res, axis=1)\n",
    "test_act = np.argmax(y_test, axis=1)\n",
    "ens_test_acc = (test_pred == test_act).mean()\n",
    "print(f'Ensemble Train Accuracy: {ens_train_acc}')\n",
    "print(f'Ensemble Test Accuracy: {ens_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 8, 4, 9, 1, 1, 2, 3, 8, 3, 8, 9, 8, 9, 1, 3, 8, 7, 1, 1, 4,\n",
       "       9, 5, 2, 7, 6, 4, 9, 9, 4, 9, 9, 4, 8, 5, 9, 6, 6, 1, 2, 1, 1, 9,\n",
       "       0, 5, 2, 8, 5, 9, 7, 1, 6, 9, 7, 6, 9, 4, 8, 9, 5, 4, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # df = pd.DataFrame()\n",
    "# pd.DataFrame(train_res).to_csv('data/train_res.csv', index=False)\n",
    "# pd.DataFrame(test_res).to_csv('data/test_res.csv', index=False)\n",
    "# x1 = pd.read_csv('data/train_res.csv')\n",
    "x1.to_numpy()[(train_pred != train_act),[train_pred[(train_pred != train_act)]]]\n",
    "x1.to_numpy()[(train_pred != train_act),[train_act[(train_pred != train_act)]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/Users/chadschupbach/opt/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 331,450\n",
      "Trainable params: 331,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = 'models/best_weights.hdf5'\n",
    "# checkpoint = ModelCheckpoint(fp, monitor='val_accuracy', save_best_only=True,\n",
    "#                              save_weights_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='nadam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.4966 - accuracy: 0.8381 - val_loss: 0.0673 - val_accuracy: 0.9805\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 52s 1ms/sample - loss: 0.1167 - accuracy: 0.9694 - val_loss: 0.0479 - val_accuracy: 0.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64e90e950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=2, verbose=1,\n",
    "          validation_split=0.2, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.537e-01,  1.163e-01, -2.180e-02,  5.100e-03],\n",
       "       [-3.100e-02,  8.900e-03, -7.500e-03,  2.300e-03],\n",
       "       [-1.320e-02,  1.800e-03,  8.200e-03, -1.200e-03],\n",
       "       [-7.900e-03,  2.800e-03, -1.910e-02,  3.900e-03],\n",
       "       [-7.700e-03,  1.600e-03,  1.330e-02, -2.000e-04],\n",
       "       [ 3.000e-04, -3.000e-04, -5.600e-03, -6.000e-04],\n",
       "       [-5.400e-03,  1.900e-03, -3.000e-03,  8.000e-04],\n",
       "       [ 1.000e-04, -3.000e-04,  4.400e-03,  7.000e-04],\n",
       "       [-1.300e-03,  1.000e-04,  2.230e-02, -5.500e-03],\n",
       "       [ 1.000e-03,  1.000e-04, -1.650e-02,  4.800e-03],\n",
       "       [-9.700e-03,  2.300e-03,  1.140e-02, -1.300e-03],\n",
       "       [ 4.300e-03, -1.200e-03, -1.760e-02,  1.900e-03],\n",
       "       [-2.500e-03,  7.000e-04,  2.000e-04, -6.000e-04],\n",
       "       [-2.300e-03,  9.000e-04, -4.600e-03,  7.000e-04],\n",
       "       [ 1.700e-03, -5.000e-04,  8.000e-04, -5.000e-04],\n",
       "       [-6.000e-04,  0.000e+00,  3.300e-03,  1.500e-03],\n",
       "       [-1.600e-03,  5.000e-04,  1.640e-02, -3.500e-03],\n",
       "       [-6.000e-04,  6.000e-04, -1.550e-02,  3.500e-03],\n",
       "       [ 4.000e-04, -1.000e-03,  1.010e-02, -2.300e-03],\n",
       "       [ 1.500e-03,  6.000e-04, -1.100e-03, -4.000e-04],\n",
       "       [-3.500e-03,  2.000e-04, -5.200e-03, -1.000e-04],\n",
       "       [-2.300e-03,  8.000e-04,  3.500e-03,  2.800e-03],\n",
       "       [ 3.200e-03, -6.000e-04,  4.300e-03, -2.200e-03],\n",
       "       [-1.400e-03,  0.000e+00, -1.020e-02,  2.700e-03],\n",
       "       [ 3.000e-04,  4.000e-04,  4.800e-03, -2.100e-03],\n",
       "       [-4.800e-03,  9.000e-04,  4.300e-03,  3.000e-04],\n",
       "       [ 4.400e-03, -9.000e-04, -8.500e-03,  6.000e-04],\n",
       "       [ 7.000e-04, -1.000e-04,  3.500e-03,  0.000e+00],\n",
       "       [-2.300e-03,  5.000e-04,  8.300e-03, -1.400e-03],\n",
       "       [ 3.700e-03, -6.000e-04,  6.000e-03,  5.000e-04],\n",
       "       [-1.200e-03, -1.000e-04,  4.700e-03,  4.000e-04],\n",
       "       [ 7.800e-03, -1.500e-03, -1.180e-02, -3.200e-03],\n",
       "       [-2.900e-03,  8.000e-04,  8.000e-04,  2.500e-03],\n",
       "       [-7.000e-03,  1.500e-03, -1.110e-02,  6.000e-04],\n",
       "       [ 1.300e-03, -7.000e-04,  1.340e-02,  1.200e-03],\n",
       "       [-4.000e-03,  1.400e-03,  2.000e-04, -1.000e-03],\n",
       "       [-3.300e-03,  7.000e-04,  1.120e-02, -2.000e-04],\n",
       "       [ 2.800e-03, -9.000e-04,  7.000e-04,  3.000e-04],\n",
       "       [ 9.300e-03, -1.600e-03, -1.280e-02, -9.000e-04],\n",
       "       [-7.500e-03,  1.000e-03,  1.460e-02,  1.100e-03],\n",
       "       [ 8.600e-03, -1.200e-03, -1.170e-02, -9.000e-04],\n",
       "       [-8.500e-03,  2.200e-03, -5.000e-03,  1.200e-03],\n",
       "       [ 2.000e-04, -6.000e-04,  2.670e-02, -1.600e-03],\n",
       "       [ 1.240e-02, -2.500e-03, -1.640e-02,  1.900e-03],\n",
       "       [-1.700e-02,  3.200e-03,  1.090e-02,  0.000e+00],\n",
       "       [ 1.050e-02, -1.100e-03, -1.320e-02,  2.000e-04],\n",
       "       [-9.800e-03,  1.400e-03,  9.600e-03,  0.000e+00],\n",
       "       [ 1.090e-02, -2.300e-03,  1.000e-03, -1.100e-03],\n",
       "       [-8.900e-03,  1.600e-03,  3.500e-03,  7.000e-04]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([\n",
    "    [0.4583, 0.8572, 0.0730, 0.9807],\n",
    "    [0.1046, 0.9735, 0.0512, 0.9858],\n",
    "    [0.0736, 0.9824, 0.0437, 0.9881],\n",
    "    [0.0604, 0.9842, 0.0519, 0.9869],\n",
    "    [0.0525, 0.9870, 0.0328, 0.9908],\n",
    "    [0.0448, 0.9886, 0.0461, 0.9906],\n",
    "    [0.0451, 0.9883, 0.0405, 0.9900],\n",
    "    [0.0397, 0.9902, 0.0375, 0.9908],\n",
    "    [0.0398, 0.9899, 0.0419, 0.9915],\n",
    "    [0.0385, 0.9900, 0.0642, 0.9860],\n",
    "    [0.0395, 0.9901, 0.0477, 0.9908],\n",
    "    [0.0298, 0.9924, 0.0591, 0.9895],\n",
    "    [0.0341, 0.9912, 0.0415, 0.9914],\n",
    "    [0.0316, 0.9919, 0.0417, 0.9908],\n",
    "    [0.0293, 0.9928, 0.0371, 0.9915],\n",
    "    [0.0310, 0.9923, 0.0379, 0.9910],\n",
    "    [0.0304, 0.9923, 0.0412, 0.9925],\n",
    "    [0.0288, 0.9928, 0.0576, 0.9890],\n",
    "    [0.0282, 0.9934, 0.0421, 0.9925],\n",
    "    [0.0286, 0.9924, 0.0522, 0.9902],\n",
    "    [0.0301, 0.9930, 0.0511, 0.9898],\n",
    "    [0.0266, 0.9932, 0.0459, 0.9897],\n",
    "    [0.0243, 0.9940, 0.0494, 0.9925],\n",
    "    [0.0275, 0.9934, 0.0537, 0.9903],\n",
    "    [0.0261, 0.9934, 0.0435, 0.9930],\n",
    "    [0.0264, 0.9938, 0.0483, 0.9909],\n",
    "    [0.0216, 0.9947, 0.0526, 0.9912],\n",
    "    [0.0260, 0.9938, 0.0441, 0.9918],\n",
    "    [0.0267, 0.9937, 0.0476, 0.9918],\n",
    "    [0.0244, 0.9942, 0.0559, 0.9904],\n",
    "    [0.0281, 0.9936, 0.0619, 0.9909],\n",
    "    [0.0269, 0.9935, 0.0666, 0.9913],\n",
    "    [0.0347, 0.9920, 0.0548, 0.9881],\n",
    "    [0.0318, 0.9928, 0.0556, 0.9906],\n",
    "    [0.0248, 0.9943, 0.0445, 0.9912],\n",
    "    [0.0261, 0.9936, 0.0579, 0.9924],\n",
    "    [0.0221, 0.9950, 0.0581, 0.9914],\n",
    "    [0.0188, 0.9957, 0.0693, 0.9912],\n",
    "    [0.0216, 0.9948, 0.0700, 0.9915],\n",
    "    [0.0309, 0.9932, 0.0572, 0.9906],\n",
    "    [0.0234, 0.9942, 0.0718, 0.9917],\n",
    "    [0.0320, 0.9930, 0.0601, 0.9908],\n",
    "    [0.0235, 0.9952, 0.0551, 0.9920],\n",
    "    [0.0237, 0.9946, 0.0818, 0.9904],\n",
    "    [0.0361, 0.9921, 0.0654, 0.9923],\n",
    "    [0.0191, 0.9953, 0.0763, 0.9923],\n",
    "    [0.0296, 0.9942, 0.0631, 0.9925],\n",
    "    [0.0198, 0.9956, 0.0727, 0.9925],\n",
    "    [0.0307, 0.9933, 0.0737, 0.9914],\n",
    "    [0.0218, 0.9949, 0.0772, 0.9921]\n",
    "])\n",
    "\n",
    "np.diff(arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(arr[1:,[1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0395 - accuracy: 0.9901 - val_loss: 0.0477 - val_accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0298 - accuracy: 0.9924 - val_loss: 0.0591 - val_accuracy: 0.9895\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0415 - val_accuracy: 0.9914\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.0417 - val_accuracy: 0.9908\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 0.0371 - val_accuracy: 0.9915\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0310 - accuracy: 0.9923 - val_loss: 0.0379 - val_accuracy: 0.9910\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.0412 - val_accuracy: 0.9925\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0288 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9890\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.0421 - val_accuracy: 0.9925\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.0522 - val_accuracy: 0.9902\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0511 - val_accuracy: 0.9898\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.0459 - val_accuracy: 0.9897\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0494 - val_accuracy: 0.9925\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0275 - accuracy: 0.9934 - val_loss: 0.0537 - val_accuracy: 0.9903\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0261 - accuracy: 0.9934 - val_loss: 0.0435 - val_accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0264 - accuracy: 0.9938 - val_loss: 0.0483 - val_accuracy: 0.9909\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0216 - accuracy: 0.9947 - val_loss: 0.0526 - val_accuracy: 0.9912\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.0441 - val_accuracy: 0.9918\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0476 - val_accuracy: 0.9918\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.0559 - val_accuracy: 0.9904\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0281 - accuracy: 0.9936 - val_loss: 0.0619 - val_accuracy: 0.9909\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.0666 - val_accuracy: 0.9913\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0347 - accuracy: 0.9920 - val_loss: 0.0548 - val_accuracy: 0.9881\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0318 - accuracy: 0.9928 - val_loss: 0.0556 - val_accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.0445 - val_accuracy: 0.9912\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0261 - accuracy: 0.9936 - val_loss: 0.0579 - val_accuracy: 0.9924\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.0581 - val_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0693 - val_accuracy: 0.9912\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.0700 - val_accuracy: 0.9915\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0309 - accuracy: 0.9932 - val_loss: 0.0572 - val_accuracy: 0.9906\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.0718 - val_accuracy: 0.9917\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 0.0601 - val_accuracy: 0.9908\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0235 - accuracy: 0.9952 - val_loss: 0.0551 - val_accuracy: 0.9920\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.0818 - val_accuracy: 0.9904\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0361 - accuracy: 0.9921 - val_loss: 0.0654 - val_accuracy: 0.9923\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.0763 - val_accuracy: 0.9923\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0296 - accuracy: 0.9942 - val_loss: 0.0631 - val_accuracy: 0.9925\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.0727 - val_accuracy: 0.9925\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 0.0737 - val_accuracy: 0.9914\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0772 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64f2a19d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1,\n",
    "#           validation_split=0.2, initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=30, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=40, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=50, verbose=1, callbacks=[checkpoint],\n",
    "          validation_data=(x_test, y_test), initial_epoch=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_metadata": {
   "date": "May 4, 2020"
  },
  "title": "CNN Architecture II"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
